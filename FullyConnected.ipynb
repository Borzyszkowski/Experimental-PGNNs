{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from laplace_equation.utils.result_generation import build_input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nominal_temperature</th>\n",
       "      <th>boundary_conditions</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>[2, 43, 24, 80, 63, 43, 23, 78, 73, 72, 20, 85...</td>\n",
       "      <td>[[ 2.         43.         24.         80.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>[60, 52, 19, 0, 28, 6, 24, 67, 24, 66, 58, 30,...</td>\n",
       "      <td>[[60.         52.         19.          0.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>[57, 24, 31, 77, 8, 96, 5, 86, 95, 43, 59, 58,...</td>\n",
       "      <td>[[57.         24.         31.         77.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>[65, 77, 61, 71, 48, 79, 32, 91, 37, 84, 69, 7...</td>\n",
       "      <td>[[65.         77.         61.         71.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>[30, 45, 40, 56, 42, 0, 13, 28, 83, 2, 53, 5, ...</td>\n",
       "      <td>[[30.         45.         40.         56.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>30</td>\n",
       "      <td>[98, 98, 98, 98, 98, 98, 98, 98, 98, 27, 27, 2...</td>\n",
       "      <td>[[98.         98.         98.         98.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>100</td>\n",
       "      <td>[41, 41, 41, 41, 41, 41, 41, 41, 41, 30, 30, 3...</td>\n",
       "      <td>[[41.         41.         41.         41.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>20</td>\n",
       "      <td>[39, 39, 39, 39, 39, 39, 39, 39, 39, 83, 83, 8...</td>\n",
       "      <td>[[39.         39.         39.         39.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>55</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 66, 66, 6...</td>\n",
       "      <td>[[43.         43.         43.         43.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>15</td>\n",
       "      <td>[27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 9, ...</td>\n",
       "      <td>[[27.         27.         27.         27.     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nominal_temperature                                boundary_conditions  \\\n",
       "0                      92  [2, 43, 24, 80, 63, 43, 23, 78, 73, 72, 20, 85...   \n",
       "1                      91  [60, 52, 19, 0, 28, 6, 24, 67, 24, 66, 58, 30,...   \n",
       "2                      27  [57, 24, 31, 77, 8, 96, 5, 86, 95, 43, 59, 58,...   \n",
       "3                      36  [65, 77, 61, 71, 48, 79, 32, 91, 37, 84, 69, 7...   \n",
       "4                      25  [30, 45, 40, 56, 42, 0, 13, 28, 83, 2, 53, 5, ...   \n",
       "...                   ...                                                ...   \n",
       "8995                   30  [98, 98, 98, 98, 98, 98, 98, 98, 98, 27, 27, 2...   \n",
       "8996                  100  [41, 41, 41, 41, 41, 41, 41, 41, 41, 30, 30, 3...   \n",
       "8997                   20  [39, 39, 39, 39, 39, 39, 39, 39, 39, 83, 83, 8...   \n",
       "8998                   55  [43, 43, 43, 43, 43, 43, 43, 43, 43, 66, 66, 6...   \n",
       "8999                   15  [27, 27, 27, 27, 27, 27, 27, 27, 27, 9, 9, 9, ...   \n",
       "\n",
       "                                                 result  \n",
       "0     [[ 2.         43.         24.         80.     ...  \n",
       "1     [[60.         52.         19.          0.     ...  \n",
       "2     [[57.         24.         31.         77.     ...  \n",
       "3     [[65.         77.         61.         71.     ...  \n",
       "4     [[30.         45.         40.         56.     ...  \n",
       "...                                                 ...  \n",
       "8995  [[98.         98.         98.         98.     ...  \n",
       "8996  [[41.         41.         41.         41.     ...  \n",
       "8997  [[39.         39.         39.         39.     ...  \n",
       "8998  [[43.         43.         43.         43.     ...  \n",
       "8999  [[27.         27.         27.         27.     ...  \n",
       "\n",
       "[9000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"laplace_equation/data/result.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for i, record in data.iterrows():\n",
    "    input_temperature = build_input_matrix(record[\"nominal_temperature\"], record[\"boundary_conditions\"])\n",
    "    input_data.append(input_temperature)    \n",
    "    \n",
    "input_data = np.asarray(input_data)\n",
    "output_data = np.load(\"laplace_equation/data/output_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_data.reshape(-1, 100), output_data.reshape(-1, 100), test_size=0.2, random_state=42)\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.fc1 = Dense(32, activation='relu')\n",
    "    self.fc2 = Dense(128, activation='relu')\n",
    "    self.fc3 = Dense(256, activation='relu')\n",
    "    self.fc4 = Dense(100)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.fc3(x)\n",
    "    x = self.fc4(x)\n",
    "    return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Accuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.Accuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_data, output_data):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(input_data, training=True)\n",
    "    loss = loss_fn(output_data, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(tf.round(output_data), tf.round(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_data, output_data):\n",
    "  predictions = model(input_data, training=False)\n",
    "  t_loss = loss_fn(output_data, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(tf.round(output_data), tf.round(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 254.18267822265625, Accuracy: 7.7384724617004395, Test Loss: 42.54594802856445, Test Accuracy: 15.328332901000977\n",
      "Epoch 2, Loss: 30.422178268432617, Accuracy: 18.850555419921875, Test Loss: 19.511070251464844, Test Accuracy: 20.91777801513672\n",
      "Epoch 3, Loss: 16.354156494140625, Accuracy: 27.651803970336914, Test Loss: 12.162492752075195, Test Accuracy: 33.56111145019531\n",
      "Epoch 4, Loss: 12.230454444885254, Accuracy: 32.4627799987793, Test Loss: 9.976943016052246, Test Accuracy: 32.051109313964844\n",
      "Epoch 5, Loss: 10.00681209564209, Accuracy: 35.84291458129883, Test Loss: 7.989902973175049, Test Accuracy: 36.42277526855469\n",
      "Epoch 6, Loss: 8.499279975891113, Accuracy: 38.45527648925781, Test Loss: 6.772518157958984, Test Accuracy: 44.15055465698242\n",
      "Epoch 7, Loss: 7.565160751342773, Accuracy: 40.01583480834961, Test Loss: 6.476013660430908, Test Accuracy: 35.078887939453125\n",
      "Epoch 8, Loss: 6.9610595703125, Accuracy: 39.649166107177734, Test Loss: 5.687795162200928, Test Accuracy: 38.66722106933594\n",
      "Epoch 9, Loss: 6.09779167175293, Accuracy: 43.596527099609375, Test Loss: 5.011270523071289, Test Accuracy: 43.74833297729492\n",
      "Epoch 10, Loss: 5.352790832519531, Accuracy: 46.253334045410156, Test Loss: 4.645230293273926, Test Accuracy: 51.65610885620117\n",
      "Epoch 11, Loss: 5.155214309692383, Accuracy: 46.00013732910156, Test Loss: 4.605986595153809, Test Accuracy: 56.87778091430664\n",
      "Epoch 12, Loss: 4.989110946655273, Accuracy: 46.64875030517578, Test Loss: 4.427151679992676, Test Accuracy: 50.97610855102539\n",
      "Epoch 13, Loss: 4.884978771209717, Accuracy: 48.54874801635742, Test Loss: 5.526275157928467, Test Accuracy: 26.596664428710938\n",
      "Epoch 14, Loss: 5.098360538482666, Accuracy: 43.27333450317383, Test Loss: 4.312993049621582, Test Accuracy: 56.708335876464844\n",
      "Epoch 15, Loss: 4.895871639251709, Accuracy: 48.10319519042969, Test Loss: 5.322309494018555, Test Accuracy: 31.476667404174805\n",
      "Epoch 16, Loss: 4.925027847290039, Accuracy: 47.35527801513672, Test Loss: 4.564631938934326, Test Accuracy: 39.53889083862305\n",
      "Epoch 17, Loss: 4.733523845672607, Accuracy: 50.11138916015625, Test Loss: 4.893351078033447, Test Accuracy: 38.963890075683594\n",
      "Epoch 18, Loss: 4.950437068939209, Accuracy: 44.16569519042969, Test Loss: 4.2014665603637695, Test Accuracy: 56.70222091674805\n",
      "Epoch 19, Loss: 4.615044593811035, Accuracy: 52.79597091674805, Test Loss: 4.340596675872803, Test Accuracy: 55.88333511352539\n",
      "Epoch 20, Loss: 4.875433921813965, Accuracy: 45.87541580200195, Test Loss: 4.270672798156738, Test Accuracy: 50.91611099243164\n",
      "Epoch 21, Loss: 4.611347198486328, Accuracy: 50.43402862548828, Test Loss: 4.451173782348633, Test Accuracy: 45.81222152709961\n",
      "Epoch 22, Loss: 4.635796546936035, Accuracy: 50.15041732788086, Test Loss: 4.18399715423584, Test Accuracy: 50.497222900390625\n",
      "Epoch 23, Loss: 4.673184871673584, Accuracy: 47.573055267333984, Test Loss: 4.112368583679199, Test Accuracy: 55.461669921875\n",
      "Epoch 24, Loss: 4.711421012878418, Accuracy: 47.38597106933594, Test Loss: 4.3779497146606445, Test Accuracy: 52.74055480957031\n",
      "Epoch 25, Loss: 4.669243812561035, Accuracy: 51.01180648803711, Test Loss: 4.209427833557129, Test Accuracy: 53.387779235839844\n",
      "Epoch 26, Loss: 4.892174243927002, Accuracy: 42.66611099243164, Test Loss: 3.71468186378479, Test Accuracy: 52.35444259643555\n",
      "Epoch 27, Loss: 3.6469130516052246, Accuracy: 50.95861053466797, Test Loss: 4.875157356262207, Test Accuracy: 27.185556411743164\n",
      "Epoch 28, Loss: 3.035724639892578, Accuracy: 56.55860900878906, Test Loss: 2.914797306060791, Test Accuracy: 49.29833221435547\n",
      "Epoch 29, Loss: 3.0198333263397217, Accuracy: 52.93180465698242, Test Loss: 2.4834787845611572, Test Accuracy: 50.570552825927734\n",
      "Epoch 30, Loss: 2.5658018589019775, Accuracy: 51.33597183227539, Test Loss: 1.6362826824188232, Test Accuracy: 57.50889205932617\n",
      "Epoch 31, Loss: 1.703954815864563, Accuracy: 57.79305648803711, Test Loss: 5.63996696472168, Test Accuracy: 13.782222747802734\n",
      "Epoch 32, Loss: 1.5881845951080322, Accuracy: 61.05666732788086, Test Loss: 1.3630903959274292, Test Accuracy: 48.323333740234375\n",
      "Epoch 33, Loss: 1.7193182706832886, Accuracy: 58.37125015258789, Test Loss: 1.2441885471343994, Test Accuracy: 72.0977783203125\n",
      "Epoch 34, Loss: 1.2161381244659424, Accuracy: 73.82347106933594, Test Loss: 1.0494606494903564, Test Accuracy: 76.81000518798828\n",
      "Epoch 35, Loss: 1.6451393365859985, Accuracy: 58.069026947021484, Test Loss: 0.9607667326927185, Test Accuracy: 81.39888763427734\n",
      "Epoch 36, Loss: 1.2051255702972412, Accuracy: 72.98027801513672, Test Loss: 0.9647470712661743, Test Accuracy: 77.99555969238281\n",
      "Epoch 37, Loss: 1.4631452560424805, Accuracy: 60.52555465698242, Test Loss: 1.3706938028335571, Test Accuracy: 52.170555114746094\n",
      "Epoch 38, Loss: 1.3002640008926392, Accuracy: 64.60417175292969, Test Loss: 1.4098663330078125, Test Accuracy: 52.842777252197266\n",
      "Epoch 39, Loss: 1.4560389518737793, Accuracy: 61.249446868896484, Test Loss: 1.3665941953659058, Test Accuracy: 66.19166564941406\n",
      "Epoch 40, Loss: 1.4158262014389038, Accuracy: 61.56264114379883, Test Loss: 1.0345553159713745, Test Accuracy: 83.02388763427734\n",
      "Epoch 41, Loss: 2.2063424587249756, Accuracy: 65.99166107177734, Test Loss: 7.292301654815674, Test Accuracy: 13.491110801696777\n",
      "Epoch 42, Loss: 1.378134846687317, Accuracy: 71.6530532836914, Test Loss: 1.0938234329223633, Test Accuracy: 77.2027816772461\n",
      "Epoch 43, Loss: 1.212738275527954, Accuracy: 71.35791778564453, Test Loss: 1.0761263370513916, Test Accuracy: 73.58721923828125\n",
      "Epoch 44, Loss: 1.2748020887374878, Accuracy: 67.32430267333984, Test Loss: 1.1054924726486206, Test Accuracy: 65.41888427734375\n",
      "Epoch 45, Loss: 1.2287694215774536, Accuracy: 71.25958251953125, Test Loss: 1.0619711875915527, Test Accuracy: 72.88055419921875\n",
      "Epoch 46, Loss: 1.3637077808380127, Accuracy: 63.99361038208008, Test Loss: 1.1118942499160767, Test Accuracy: 64.98833465576172\n",
      "Epoch 47, Loss: 1.4230828285217285, Accuracy: 66.09722137451172, Test Loss: 1.0061473846435547, Test Accuracy: 73.4927749633789\n",
      "Epoch 48, Loss: 1.3633383512496948, Accuracy: 62.99694061279297, Test Loss: 1.1135956048965454, Test Accuracy: 64.84944152832031\n",
      "Epoch 49, Loss: 1.3638992309570312, Accuracy: 63.26958465576172, Test Loss: 2.0983736515045166, Test Accuracy: 42.423336029052734\n",
      "Epoch 50, Loss: 1.4218682050704956, Accuracy: 64.57514190673828, Test Loss: 1.1663365364074707, Test Accuracy: 74.19833374023438\n",
      "Epoch 51, Loss: 1.3105627298355103, Accuracy: 64.69819641113281, Test Loss: 1.4407750368118286, Test Accuracy: 61.0966682434082\n",
      "Epoch 52, Loss: 1.2028619050979614, Accuracy: 70.70263671875, Test Loss: 1.1585713624954224, Test Accuracy: 65.20111083984375\n",
      "Epoch 53, Loss: 1.3319835662841797, Accuracy: 65.5138931274414, Test Loss: 0.9672417044639587, Test Accuracy: 78.70333099365234\n",
      "Epoch 54, Loss: 1.3156036138534546, Accuracy: 64.0977783203125, Test Loss: 1.1197813749313354, Test Accuracy: 70.96221923828125\n",
      "Epoch 55, Loss: 1.3133015632629395, Accuracy: 66.7437515258789, Test Loss: 1.0395514965057373, Test Accuracy: 71.6449966430664\n",
      "Epoch 56, Loss: 1.5139522552490234, Accuracy: 60.44916534423828, Test Loss: 1.1122915744781494, Test Accuracy: 74.61555480957031\n",
      "Epoch 57, Loss: 1.176058053970337, Accuracy: 74.10083770751953, Test Loss: 0.9741348028182983, Test Accuracy: 77.42000579833984\n",
      "Epoch 58, Loss: 1.4318896532058716, Accuracy: 63.674442291259766, Test Loss: 1.0403015613555908, Test Accuracy: 71.50277709960938\n",
      "Epoch 59, Loss: 1.1890630722045898, Accuracy: 71.69791412353516, Test Loss: 1.1365320682525635, Test Accuracy: 68.34333801269531\n",
      "Epoch 60, Loss: 1.4080256223678589, Accuracy: 62.92222213745117, Test Loss: 1.1943719387054443, Test Accuracy: 62.293331146240234\n",
      "Epoch 61, Loss: 1.602331519126892, Accuracy: 58.59138870239258, Test Loss: 1.1041381359100342, Test Accuracy: 68.4544448852539\n",
      "Epoch 62, Loss: 1.1283535957336426, Accuracy: 76.46292114257812, Test Loss: 1.0495249032974243, Test Accuracy: 73.59832763671875\n",
      "Epoch 63, Loss: 1.287428617477417, Accuracy: 66.1361083984375, Test Loss: 1.366855502128601, Test Accuracy: 67.59222412109375\n",
      "Epoch 64, Loss: 1.2652772665023804, Accuracy: 68.34124755859375, Test Loss: 1.0909419059753418, Test Accuracy: 79.48110961914062\n",
      "Epoch 65, Loss: 1.2764052152633667, Accuracy: 67.14791870117188, Test Loss: 1.0046932697296143, Test Accuracy: 74.67832946777344\n",
      "Epoch 66, Loss: 1.2907098531723022, Accuracy: 67.33541870117188, Test Loss: 1.386547327041626, Test Accuracy: 53.93278121948242\n",
      "Epoch 67, Loss: 1.4297926425933838, Accuracy: 65.132080078125, Test Loss: 0.9966024160385132, Test Accuracy: 79.6050033569336\n",
      "Epoch 68, Loss: 1.2303019762039185, Accuracy: 70.6280517578125, Test Loss: 1.083460807800293, Test Accuracy: 70.85944366455078\n",
      "Epoch 69, Loss: 1.1303521394729614, Accuracy: 70.69027709960938, Test Loss: 1.116808295249939, Test Accuracy: 64.7683334350586\n",
      "Epoch 70, Loss: 1.2406255006790161, Accuracy: 66.14680480957031, Test Loss: 1.1380048990249634, Test Accuracy: 61.51611328125\n",
      "Epoch 71, Loss: 1.4541980028152466, Accuracy: 56.26778030395508, Test Loss: 3.623314380645752, Test Accuracy: 29.501667022705078\n",
      "Epoch 72, Loss: 1.3297888040542603, Accuracy: 67.6522216796875, Test Loss: 1.8403059244155884, Test Accuracy: 54.693336486816406\n",
      "Epoch 73, Loss: 1.3220107555389404, Accuracy: 64.7762451171875, Test Loss: 0.9926803708076477, Test Accuracy: 78.83444213867188\n",
      "Epoch 74, Loss: 1.235927700996399, Accuracy: 69.33027648925781, Test Loss: 1.6442078351974487, Test Accuracy: 47.747222900390625\n",
      "Epoch 75, Loss: 1.370439887046814, Accuracy: 64.58833312988281, Test Loss: 3.479971408843994, Test Accuracy: 29.050556182861328\n",
      "Epoch 76, Loss: 1.1390302181243896, Accuracy: 64.38874816894531, Test Loss: 0.9120321869850159, Test Accuracy: 66.0433349609375\n",
      "Epoch 77, Loss: 0.8113153576850891, Accuracy: 63.399864196777344, Test Loss: 0.4217839241027832, Test Accuracy: 75.49221801757812\n",
      "Epoch 78, Loss: 0.4907747805118561, Accuracy: 67.59931182861328, Test Loss: 0.402376651763916, Test Accuracy: 60.81500244140625\n",
      "Epoch 79, Loss: 0.4393206536769867, Accuracy: 69.44194793701172, Test Loss: 0.5237125754356384, Test Accuracy: 49.942222595214844\n",
      "Epoch 80, Loss: 0.35506078600883484, Accuracy: 64.63444519042969, Test Loss: 0.16650508344173431, Test Accuracy: 78.35778045654297\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 80\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for input_temperature, output_temperature in train_dataset:\n",
    "    train_step(input_temperature, output_temperature)\n",
    "\n",
    "  for input_temperature, output_temperature in test_dataset:\n",
    "    test_step(input_temperature, output_temperature)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print(template.format(epoch + 1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result() * 100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
